{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **RECORDLINKAGE  TOOL**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import recordlinkage\n",
    "import mlxtend\n",
    "import random\n",
    "import pickle\n",
    "import shapash \n",
    "\n",
    "from shapash.explainer.smart_explainer import SmartExplainer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score\n",
    "from lightgbm import LGBMClassifier\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from recordlinkage import datasets\n",
    "from codecarbon import EmissionsTracker\n",
    "tracker = EmissionsTracker()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Loading datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_febrl_dataset, second_febrl_dataset = datasets.load_febrl4(return_links=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes_frst_febrl_dataset = sorted(first_febrl_dataset.index)\n",
    "indexes_scd_febrl_dataset = sorted(second_febrl_dataset.index)\n",
    "tuples_true_links = list(zip(indexes_frst_febrl_dataset, indexes_scd_febrl_dataset))\n",
    "true_links = pd.MultiIndex.from_tuples(tuples_true_links, names=('org_data', 'dpl_data'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_febrl_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_febrl_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **ETAPE D'INDEXING**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'indexation n'est faisable que sur **un** ou **deux** jeu de données. Il propose 4 méthodes d'indexations:\n",
    "- Full : renvoie toutes les combinaisons de paires possibles\n",
    "- Block : renvoie tous les éléments qui concordent par rapport aux variables données en entrée \n",
    "- SortedNeighbourhood : renvoie tous les éléments qui concordent par rapport aux variables données en entrée et celles dans leur voisinnage\n",
    "- Random : renvoi des paires crées aléatoirement\n",
    "\n",
    "Ici, nous testons la méthode du block en utilisant les colonnes 'given_name', 'address_1' et 'date_of_birth'. Les candidats seront filtrés pour n'inclure que ceux dont les valeurs sont égales sur une ou plusieurs de ces colonnes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'étape d'indexation est cruciale. Plus on donne entrée des informations précises, meilleure est la selection de paires de candidats à comparer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour évaluer les résultats de la méthode d'indexation, nous regardons deux élements:\n",
    "- le pourcentage de paires dupliquées detctées par la méthode d'indexation utilisée\n",
    "- la performance de la méthode en fonction du nombre de blocking key données en entrée\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Méthode du block**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_block_indexing(blocking_key: list):\n",
    "    indexer = recordlinkage.Index()\n",
    "    for column in blocking_key:\n",
    "        indexer.block(on=column)\n",
    "        pairs_to_comp = indexer.index(first_febrl_dataset, second_febrl_dataset)\n",
    "        real_link_found = pairs_to_comp & true_links\n",
    "        print(\"Nombre de paires sélectionnées: {}\".format(len(pairs_to_comp)))\n",
    "        print(\"Pourcentage de vraies paires selctionnées: {}%.\".format(len(real_link_found)/len(true_links)*100))\n",
    "        \n",
    "    return pairs_to_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_to_comp_block = test_block_indexing(['given_name', 'address_1', 'date_of_birth'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plus il y a de colonnes, plus les paires sélectionnées sont réalistes et améliorent les scores de classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ressemblance des paires selectionnées**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_color():\n",
    "    rgbl=['yellow','red','green']\n",
    "    return random.choice(rgbl)\n",
    "\n",
    "def selected_pairs_values(list_tuple:list):\n",
    "    selected_pairs_values_df = pd.DataFrame(columns=first_febrl_dataset.columns)\n",
    "    for tpl in list_tuple:\n",
    "        first_candidate = first_febrl_dataset.iloc[first_febrl_dataset.index.isin([tpl[0]])]\n",
    "        second_candidate = second_febrl_dataset.iloc[second_febrl_dataset.index.isin([tpl[1]])]\n",
    "        concat_df = pd.concat([first_candidate, second_candidate])\n",
    "        #candidates_df = candidates_df.style.applymap(lambda x: 'background-color: yellow' if True else '')\n",
    "        \n",
    "        selected_pairs_values_df = pd.concat([selected_pairs_values_df, concat_df])\n",
    "    return selected_pairs_values_df \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "selected_pairs_values(pairs_to_comp_block[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Méthode du SortedNeighborhood**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans le cas ou les données sont susceptible de contenir des erreurs de typographies, utiliser la méthode SortedNeighborhood peut ajouter une certaine flexibilité pour les fautes d'orthographe mineures. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_sorted_neighbourhood_indexing(blocking_key: list):\n",
    "    for column in blocking_key:\n",
    "        indexer = recordlinkage.SortedNeighbourhoodIndex(column)\n",
    "        pairs_to_comp = indexer.index(first_febrl_dataset, second_febrl_dataset)\n",
    "        real_link_found = pairs_to_comp & true_links\n",
    "        print(\"Nombre de paires sélectionnées: {}\".format(len(pairs_to_comp)))\n",
    "        print(\"Pourcentage de vraies paires selctionnées: {}%.\".format(len(real_link_found)/len(true_links)*100))\n",
    "        \n",
    "    return pairs_to_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_to_comp_sn = test_sorted_neighbourhood_indexing(['given_name', 'address_1', 'date_of_birth', 'soc_sec_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La méthode basée sur le voisinnage à besoin de plus d'information pour avoir une bonne record rapport."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**COMPARAISON**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La méthode suivante consiste à comparer les paires en utilisant Compare. </br>\n",
    "Nous pouvons définir plusieurs options pour la façon dont nous voulons comparer les colonnes de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp = recordlinkage.Compare()\n",
    "\n",
    "# initialise similarity measurement algorithms\n",
    "comp.string('given_name', 'given_name', method='jarowinkler')\n",
    "comp.string('surname', 'surname', method='jarowinkler')\n",
    "comp.string('address_1', 'address_1', method='levenshtein')\n",
    "comp.exact('soc_sec_id', 'soc_sec_id')\n",
    "\n",
    "# the method .compute() returns the DataFrame with the feature vectors.\n",
    "comp_scores_vec = comp.compute(pairs_to_comp_block, first_febrl_dataset, second_febrl_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_scores_vec['tupled_index'] = comp_scores_vec.index.tolist()\n",
    "comp_scores_vec['label'] = comp_scores_vec['tupled_index'].apply(lambda x: 1 if x in true_links else 0)\n",
    "comp_scores_vec.columns = ['given_name_score', 'surname_score', 'address_1_score', 'soc_sec_id_score', 'tupled_index', 'label']\n",
    "\n",
    "comp_scores_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(comp_scores_vec, test_size=0.25)\n",
    "classifier = LGBMClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(train)\n",
    "Y_train = train['label']\n",
    "X_train = train[['given_name_score', 'surname_score', 'address_1_score', 'soc_sec_id_score']]\n",
    "Y_test = test['label']\n",
    "X_test = test[['given_name_score', 'surname_score', 'address_1_score', 'soc_sec_id_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.fit(X_train, Y_train)\n",
    "predictions = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(Y_test, predictions):\n",
    "    print(\"Rappel: {}\".format(recall_score(Y_test, predictions)))\n",
    "    print(\"Precision: {}\".format(precision_score(Y_test, predictions)))\n",
    "    print(\"Accuracy: {}\".format(accuracy_score(Y_test, predictions)))\n",
    "    \n",
    "    plot_confusion_matrix(confusion_matrix(Y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation(Y_test, predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Human review**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(X_train))\n",
    "print(len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = {\n",
    "     'given_name_score': 'given_name_score',\n",
    "     'surname_score': 'surname_score',\n",
    "     'address_1_score': 'address_1_score',\n",
    "     'soc_sec_id_score': 'soc_sec_id_score'\n",
    "}\n",
    "interpretable_train = train[['given_name_score', 'surname_score', 'address_1_score', 'soc_sec_id_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapash.explainer.smart_explainer import SmartExplainer\n",
    "xpl = SmartExplainer(features_dict=features) # optional parameter\n",
    "xpl.compile(\n",
    "    x=X_test,\n",
    "    model=classifier,\n",
    "    y_pred= Y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = xpl.run_app(title_story='Dupliacte Matches')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = {'given_name': '',\n",
    " 'surname': '',\n",
    " 'street_number': '',\n",
    " 'address_1': '',\n",
    " 'address_2': '',\n",
    " 'suburb': '',\n",
    " 'postcode': '',\n",
    " 'state': '',\n",
    " 'date_of_birth': '',\n",
    " 'soc_sec_id': ''}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapash.explainer.smart_explainer import SmartExplainer\n",
    "xpl = SmartExplainer(features_dict=features) # optional parameter\n",
    "xpl.compile(\n",
    "    x=train,\n",
    "    model=clf,\n",
    "    y_pred=predictions_monoindex['label']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = recordlinkage.confusion_matrix(test_matches_index, predictions, len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(confusion_matrix);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_candidates_from_false_negatif_prediction():\n",
    "    false_negatif_df = pd.DataFrame(columns = first_febrl_dataset.columns)\n",
    "    predicted_non_match = list(set(test.index) - set(predictions))\n",
    "    # format change\n",
    "    predicted_non_match = pd.MultiIndex.from_tuples(predicted_non_match, names=('org', 'dup'))\n",
    "    false_negatif = predicted_non_match & true_links \n",
    "        \n",
    "    for tpl in false_negatif: \n",
    "        first_candidate = first_febrl_dataset.iloc[first_febrl_dataset.index.isin([tpl[0]])]\n",
    "        second_candidate = second_febrl_dataset.iloc[second_febrl_dataset.index.isin([tpl[1]])]\n",
    "        false_negatif_df = pd.concat([false_negatif_df, first_candidate, second_candidate])\n",
    "    return false_negatif_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_candidates_from_false_negatif_prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_candidates_from_false_positif_prediction():\n",
    "    false_positif_df = pd.DataFrame(columns = first_febrl_dataset.columns)\n",
    "    false_positif = list(set(predictions) - set(true_links))\n",
    "    \n",
    "    for tpl in false_positif: \n",
    "        first_candidate = first_febrl_dataset.iloc[first_febrl_dataset.index.isin([tpl[0]])]\n",
    "        second_candidate = second_febrl_dataset.iloc[second_febrl_dataset.index.isin([tpl[1]])]\n",
    "        false_positif_df = pd.concat([false_positif_df, first_candidate, second_candidate])\n",
    "    return false_positif_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faux_positifs = select_candidates_from_false_positif_prediction()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EVALUATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faux_positifs.columns\n",
    "faux_positifs_dict = dict(zip(faux_positifs.columns, ['']*len(faux_positifs.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faux_positifs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(predictions))\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapash.explainer.smart_explainer import SmartExplainer\n",
    "xpl = SmartExplainer(features_dict=faux_positifs_dict) # optional parameter\n",
    "xpl.compile(\n",
    "    x=train,\n",
    "    model=clf,\n",
    "    y_pred=predictions\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(true_links_, pred_links):\n",
    "    print(\"Rappel: {}\".format(sklearn.recall(true_links, predictions)))\n",
    "    print(\"Precision: {}\".format(sklearn.precision(true_links, predictions)))\n",
    "    print(\"Accuracy: {}\".format(sklearn.accuracy(true_links, predictions, comp_scores_vec.index)))\n",
    "    \n",
    "    confusion_matrix = recordlinkage.confusion_matrix(golden_match_index_test, link_pred, len(comp_scores_vec_test))\n",
    "    plot_confusion_matrix(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evaluation(true_links, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **CLASSIFICATION NON SUPERVISEE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_km = recordlinkage.KMeansClassifier()\n",
    "predict_links_km = model_km.fit_predict(comparison_vectors=comp_scores_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix_km = recordlinkage.confusion_matrix(true_links, predict_links_km, len(comp_scores_vec))\n",
    "plot_confusion_matrix(confusion_matrix_km);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Carbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Aucun(e)",
  "kernelspec": {
   "display_name": "tdf_innov2",
   "language": "python",
   "name": "tdf_innov2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
